const API_BASE = 'https://pimentas-api.onrender.com'; // <- sua API no Render


# main.py — Pimentas App (YOLOv8 + Chat com IA/JSON/Web-RAG)
# UI clara, sem "Pronto" e sem painel de "Resumo".
# Chat: JSON local -> IA com contexto (se DOC existir) -> IA geral (opcional) -> Web-RAG (opcional).

import os, io, time, threading, base64, uuid, json
from typing import Optional
# main.py — API e UI de Identificação de Pimentas com chat
# - YOLOv8 (ultralytics) em CPU
# - UI clara, sem painel de "Resumo/Pronto"
# - /info: chat baseado em JSON local; IA (OpenAI) e Tavily opcionais
# - Compatível com WebView (Kodular/App Inventor)

import os, io, time, threading, base64, requests, uuid, json
from typing import List, Optional
from urllib.parse import urlparse

import requests
from fastapi import FastAPI, UploadFile, File, Response
from fastapi.responses import JSONResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
os.environ.setdefault("OMP_NUM_THREADS", "2")
os.environ.setdefault("MKL_NUM_THREADS", "2")

# YOLO opcional: o app sobe mesmo sem o pacote
try:
    from ultralytics import YOLO
    _ULTRA = True
except Exception:
    YOLO = None
    _ULTRA = False
from fastapi import FastAPI, UploadFile, File, Response, Request
from fastapi.responses import JSONResponse, HTMLResponse, FileResponse
from fastapi.staticfiles import StaticFiles

from PIL import Image
import numpy as np
from ultralytics import YOLO

app = FastAPI(title="API Pimentas YOLOv8")

app = FastAPI(title="Pimentas App")
# ===================== CONFIG =====================

# ----------------- Config -----------------
MODEL_URL = os.getenv(
    "MODEL_URL",
    "https://huggingface.co/bulipucca/pimentas-model/resolve/main/best.onnx"
)
MODEL_PATH = os.path.basename(urlparse(MODEL_URL).path) if MODEL_URL else "best.onnx"
MODEL_PATH = (
    os.path.basename(urlparse(MODEL_URL).path)
    if MODEL_URL and not MODEL_URL.startswith("COLE_AQUI")
    else "best.pt"
)

PRESET = os.getenv("PRESET", "ULTRA")
PRESETS = {
    "ULTRA":       dict(imgsz=320, conf=0.35, iou=0.50, max_det=16),
    "RAPIDO":      dict(imgsz=384, conf=0.30, iou=0.50, max_det=12),
    "EQUILIBRADO": dict(imgsz=448, conf=0.30, iou=0.50, max_det=16),
    "PRECISO":     dict(imgsz=512, conf=0.40, iou=0.55, max_det=20),
    "MAX_RECALL":  dict(imgsz=640, conf=0.12, iou=0.45, max_det=24),
    "ULTRA":       dict(imgsz=320, conf=0.35, iou=0.50, max_det=8),
    "RAPIDO":      dict(imgsz=384, conf=0.30, iou=0.50, max_det=8),
    "EQUILIBRADO": dict(imgsz=448, conf=0.30, iou=0.50, max_det=8),
    "PRECISO":     dict(imgsz=512, conf=0.40, iou=0.55, max_det=8),
    "MAX_RECALL":  dict(imgsz=640, conf=0.15, iou=0.45, max_det=12),
}
CFG = PRESETS.get(PRESET, PRESETS["ULTRA"])
CFG = PRESETS["ULTRA"]

RETURN_IMAGE = True

HF_TOKEN = os.getenv("HF_TOKEN", "").strip()
REQ_HEADERS = {"Authorization": f"Bearer {HF_TOKEN}"} if HF_TOKEN else {}

@@ -50,28 +52,34 @@
os.makedirs(ANNOT_DIR, exist_ok=True)
app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")

OPENAI_API_KEY    = os.getenv("OPENAI_API_KEY", "").strip()
ENABLE_GENERAL_AI = os.getenv("ENABLE_GENERAL_AI", "0") == "1"   # /ai_general
ENABLE_WEB_RAG    = os.getenv("ENABLE_WEB_RAG", "0") == "1"     # /webqa
TAVILY_API_KEY    = os.getenv("TAVILY_API_KEY", "").strip()
OPENAI_KEY   = os.getenv("OPENAI_API_KEY", "").strip()
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
TAVILY_KEY   = os.getenv("TAVILY_API_KEY", "").strip()

# ===================== ESTADO GLOBAL =====================

# ----------------- Estado -----------------
model: Optional["YOLO"] = None
model = None
labels = {}
READY = False
LOAD_ERR = None

# ----------------- Helpers -----------------
# ===================== AUX =====================

def ensure_model_file():
    if os.path.exists(MODEL_PATH) or not _ULTRA:
    if os.path.exists(MODEL_PATH):
        return
    if not MODEL_URL or MODEL_URL.startswith("COLE_AQUI"):
        raise RuntimeError("Defina MODEL_URL com link direto do modelo (.pt ou .onnx).")
    print(f"[init] Baixando modelo: {MODEL_URL}")
    with requests.get(MODEL_URL, headers=REQ_HEADERS, stream=True, timeout=600) as r:
        r.raise_for_status()
        with open(MODEL_PATH, "wb") as f:
            for chunk in r.iter_content(8192):
                if chunk: f.write(chunk)
            for chunk in r.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
    print("[init] Download concluído:", MODEL_PATH)

def _to_b64_png(np_bgr: np.ndarray) -> Optional[str]:
def to_b64_png(np_bgr: np.ndarray) -> Optional[str]:
    try:
        rgb = np_bgr[:, :, ::-1]
        buf = io.BytesIO()
@@ -84,251 +92,658 @@ def background_load():
    global model, labels, READY, LOAD_ERR
    try:
        t0 = time.time()
        if _ULTRA:
            ensure_model_file()
            m = YOLO(MODEL_PATH)
            try: m.fuse()
            except: pass
            model = m
            labels = m.names
        ensure_model_file()
        m = YOLO(MODEL_PATH)
        try:
            m.fuse()
        except Exception:
            pass
        model = m
        labels = m.names
        READY = True
        print(f"[init] pronto em {time.time()-t0:.1f}s (ultra={_ULTRA})")
        print(f"[init] Modelo pronto em {time.time() - t0:.1f}s")
    except Exception as e:
        LOAD_ERR = str(e)
        READY = False
        print("[init] erro:", LOAD_ERR)
        print("[init] ERRO ao carregar modelo:", LOAD_ERR)

@app.on_event("startup")
def on_startup():
    threading.Thread(target=background_load, daemon=True).start()

# ----------------- Health -----------------
# ===================== ENDPOINTS BÁSICOS =====================

@app.get("/")
def health():
    return {
        "status": "ok" if READY else "warming",
        "ready": READY,
        "error": LOAD_ERR,
        "model": MODEL_PATH if MODEL_PATH else None,
        "classes": list(labels.values()) if READY and labels else None,
        "classes": list(labels.values()) if READY else None,
    }

@app.head("/")
def head():
def health_head():
    return Response(status_code=200)

# ----------------- KB (debug) -----------------
@app.get("/kb.json")
def kb_json():
    p = os.path.join(STATIC_DIR, "pepper_info.json")
    if not os.path.exists(p):
        return JSONResponse({"detail": "pepper_info.json não encontrado em /static"}, status_code=404)
    with open(p, "r", encoding="utf-8") as f:
        data = json.load(f)
    return JSONResponse(data)

# ----------------- IA helpers -----------------
def _openai_chat(messages, model="gpt-4o-mini", temperature=0.2, max_tokens=500) -> str:
    """Retorna string ou '' (silenciosa em falha)."""
    if not OPENAI_API_KEY:
        return ""
    try:
        r = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers={"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type":"application/json"},
            json={"model": model, "temperature": temperature, "max_tokens": max_tokens, "messages": messages},
            timeout=30
        )
        j = r.json()
        if isinstance(j, dict) and j.get("choices"):
            return (j["choices"][0]["message"]["content"] or "").strip()
        return ""
    except Exception:
        return ""

def _tavily_search(q: str, k: int = 5) -> str:
    if not (ENABLE_WEB_RAG and TAVILY_API_KEY): return ""
    try:
        r = requests.post(
            "https://api.tavily.com/search",
            json={"api_key": TAVILY_API_KEY, "query": q, "max_results": k, "include_answer": True},
            timeout=30
        )
        j = r.json()
        if j.get("answer"): return j["answer"].strip()
        if "results" in j and j["results"]:
            tops = []
            for it in j["results"][:k]:
                title = it.get("title","")
                url   = it.get("url","")
                snippet = it.get("content","")
                tops.append(f"- {title}: {snippet} ({url})")
            return "Resumo Web:\n" + "\n".join(tops)
        return ""
    except Exception:
        return ""

# ----------------- IA endpoints -----------------
@app.post("/ai")
def ai_local(payload: dict):
    pepper = payload.get("pepper","").strip()
    q      = payload.get("q","").strip()

    # Carrega KB local
    kb = {}
    p = os.path.join(STATIC_DIR, "pepper_info.json")
    if os.path.exists(p):
        try:
            with open(p, "r", encoding="utf-8") as f:
                kb = json.load(f)
        except:
            kb = {}

    # Seleciona doc (match simples; no front há normalização extra)
    doc = None
    if isinstance(kb, dict):
        for k in kb.keys():
            if k.lower()==pepper.lower() or pepper.lower() in k.lower() or k.lower() in pepper.lower():
                doc = kb[k]; break

    # IA com contexto (se houver)
    if doc:
        sys = ("Você é um assistente curto e direto. "
               "Responda em PT-BR com base no JSON fornecido (se compatível) e use parágrafos curtos.")
        user = f"Pergunta: {q}\n\nContexto: {json.dumps(doc, ensure_ascii=False)}"
        text = _openai_chat(
            [{"role":"system","content":sys}, {"role":"user","content":user}]
        )
        return JSONResponse({"ok": bool(text), "text": text or ""})

    return JSONResponse({"ok": False, "text": ""})

@app.post("/ai_general")
def ai_general(payload: dict):
    if not ENABLE_GENERAL_AI:
        return JSONResponse({"ok": False, "text": ""})
    q = payload.get("q","")
    sys = "Responda em PT-BR, objetivo, até 4 linhas."
    text = _openai_chat(
        [{"role":"system","content":sys}, {"role":"user","content":q}],
        max_tokens=300
    )
    return JSONResponse({"ok": bool(text), "text": text or ""})

@app.post("/webqa")
def webqa(payload: dict):
    q = payload.get("q","")
    ans = _tavily_search(q)
    if not ans: return JSONResponse({"ok": False, "text": ""})
    if OPENAI_API_KEY:
        text = _openai_chat(
            [{"role":"system","content":"Resuma em até 4 linhas, cite fonte entre parênteses quando possível."},
             {"role":"user","content":ans}],
            max_tokens=300
        )
        return JSONResponse({"ok": True, "text": text or ans})
    return JSONResponse({"ok": True, "text": ans})
@app.get("/warmup")
def warmup():
    t0 = time.time()
    while not READY and time.time() - t0 < 90:
        time.sleep(0.5)
    if not READY:
        return {"ok": False, "warming_up": True}
    img = Image.new("RGB", (64, 64), (255, 255, 255))
    _ = model.predict(img, imgsz=CFG["imgsz"], conf=CFG["conf"], iou=CFG["iou"],
                      max_det=1, device="cpu", verbose=False)
    return {"ok": True}

# ----------------- Predição -----------------
@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    if not READY:
        return JSONResponse({"ok": False, "warming_up": True, "error": LOAD_ERR}, status_code=503)

    t0 = time.time()
    try:
        im_bytes = await file.read()
        image = Image.open(io.BytesIO(im_bytes)).convert("RGB")
        image.thumbnail((1024,1024))

        preds = []
        image_b64 = None
        image_url = None

        if _ULTRA and model is not None:
            r = model.predict(image, imgsz=CFG["imgsz"], conf=CFG["conf"], iou=CFG["iou"],
                              max_det=CFG["max_det"], device="cpu", verbose=False)[0]
            if r.boxes is not None and len(r.boxes)>0:
                xyxy = r.boxes.xyxy.cpu().numpy().tolist()
                cls  = r.boxes.cls.cpu().numpy().astype(int).tolist()
                conf = r.boxes.conf.cpu().numpy().tolist()
                for (x1,y1,x2,y2),c,cf in zip(xyxy,cls,conf):
                    preds.append({
                        "classe": labels.get(int(c), str(int(c))) if labels else str(int(c)),
                        "conf": round(float(cf),4),
                        "bbox_xyxy":[round(x1,2),round(y1,2),round(x2,2),round(y2,2)]
                    })
                if RETURN_IMAGE:
                    annotated = r.plot()
                    fname = f"{uuid.uuid4().hex}.png"
                    fpath = os.path.join(ANNOT_DIR, fname)
                    Image.fromarray(annotated[:, :, ::-1]).save(fpath)
                    image_url = f"/static/annotated/{fname}"
                    image_b64 = _to_b64_png(annotated)

        top = max(preds, key=lambda p:p["conf"]) if preds else None
        image.thumbnail((1024, 1024))

        res = model.predict(
            image,
            imgsz=CFG["imgsz"],
            conf=CFG["conf"],
            iou=CFG["iou"],
            max_det=CFG["max_det"],
            device="cpu",
            verbose=False,
        )
        r = res[0]
        preds: List[dict] = []

        if r.boxes is not None and len(r.boxes) > 0:
            xyxy = r.boxes.xyxy.cpu().numpy().tolist()
            cls  = r.boxes.cls.cpu().numpy().astype(int).tolist()
            conf = r.boxes.conf.cpu().numpy().tolist()
            for (x1, y1, x2, y2), c, cf in zip(xyxy, cls, conf):
                preds.append({
                    "classe": labels.get(int(c), str(int(c))),
                    "conf": round(float(cf), 4),
                    "bbox_xyxy": [round(x1,2), round(y1,2), round(x2,2), round(y2,2)]
                })

            image_b64 = None
            image_url = None

            if RETURN_IMAGE:
                annotated = r.plot()  # np.ndarray (BGR)
                fname = f"{uuid.uuid4().hex}.png"
                fpath = os.path.join(ANNOT_DIR, fname)
                Image.fromarray(annotated[:, :, ::-1]).save(fpath)
                image_url = f"/static/annotated/{fname}"
                image_b64 = to_b64_png(annotated)

            top = max(preds, key=lambda p: p["conf"]) if preds else None
            return JSONResponse({
                "ok": True,
                "inference_time_s": round(time.time() - t0, 3),
                "num_dets": len(preds),
                "top_pred": top,
                "preds": preds,
                "image_b64": image_b64,
                "image_url": image_url
            })

        return JSONResponse({
            "ok": True,
            "inference_time_s": round(time.time()-t0,3),
            "num_dets": len(preds),
            "top_pred": top,
            "preds": preds,
            "image_b64": image_b64,
            "image_url": image_url
            "inference_time_s": round(time.time() - t0, 3),
            "num_dets": 0,
            "top_pred": None,
            "preds": [],
            "image_b64": None,
            "image_url": None
        })

    except Exception as e:
        return JSONResponse({"ok": False, "error": str(e), "inference_time_s": round(time.time()-t0,3)})
        return JSONResponse({"ok": False, "error": str(e),
                             "inference_time_s": round(time.time() - t0, 3)}, status_code=200)

# ============== Proxies úteis para depurar base local ==============

@app.get("/kb.json")
def kb_json():
    f = os.path.join(STATIC_DIR, "pepper_info.json")
    if not os.path.exists(f):
        return JSONResponse({"detail":"pepper_info.json não encontrado em /static"}, status_code=404)
    return FileResponse(f, media_type="application/json")

# ===================== UI PRINCIPAL =====================

@app.get("/ui")
def ui():
    html = r"""
<!doctype html>
<html lang="pt-br">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"/>
  <title>Identificação de Pimentas</title>
  <link rel="icon" href="/static/pimenta-logo.png" type="image/png" sizes="any">
  <style>
    :root{ --bg:#f7fafc; --card:#ffffff; --fg:#0f172a; --muted:#475569; --line:#e2e8f0; --accent:#16a34a; }
    *{box-sizing:border-box}
    html,body{ margin:0;background:var(--bg);color:var(--fg);font:400 16px/1.45 system-ui,-apple-system,Segoe UI,Roboto }
    .wrap{max-width:980px;margin:auto;padding:20px 14px 20px}
    header{display:flex;align-items:center;gap:10px}
    header h1{font-size:22px;margin:0}
    .card{background:var(--card);border:1px solid var(--line);border-radius:16px;padding:16px;box-shadow:0 4px 24px rgba(15,23,42,.06)}
    .btn{appearance:none;border:1px solid var(--line);background:#fff;color:var(--fg);padding:10px 14px;border-radius:12px;cursor:pointer;font-weight:600}
    .btn[disabled]{opacity:.6;cursor:not-allowed}
    .btn.accent{background:var(--accent);border-color:var(--accent);color:#fff}
    .row{display:flex;gap:10px;flex-wrap:wrap;align-items:center}
    .tip{color:var(--muted);font-size:13px}
    .imgwrap{background:#fff;border:1px solid var(--line);border-radius:12px;padding:8px}
    img,video,canvas{max-width:100%;display:block;border-radius:10px}
  </style>
</head>
<body>
  <div class="wrap">
    <header>
      <img src="/static/pimenta-logo.png" alt="Logo" width="28" height="28" onerror="this.style.display='none'">
      <h1>Identificação de Pimentas</h1>
    </header>

    <section class="card" style="margin-top:12px">
      <div class="row">
        <button id="btnPick" class="btn">Escolher imagem</button>
        <input id="fileGallery" type="file" accept="image/*" style="display:none"/>
        <input id="fileCamera"  type="file" accept="image/*" capture="environment" style="display:none"/>

        <button id="btnCam" class="btn">Abrir câmera</button>
        <button id="btnShot" class="btn" style="display:none">Capturar</button>

        <button id="btnSend" class="btn accent" disabled>Identificar</button>
        <button id="btnChat" class="btn" style="display:none">Conversar sobre a pimenta</button>
      </div>
      <p class="tip" style="margin-top:6px">A imagem é comprimida (~1024px) antes do envio para acelerar.</p>

      <div class="row" style="margin-top:10px">
        <div class="imgwrap" style="flex:1">
          <small class="tip">Original</small>
          <video id="video" autoplay playsinline style="display:none"></video>
          <img id="preview" alt="preview" style="display:none"/>
          <canvas id="canvas" style="display:none"></canvas>
        </div>
        <div class="imgwrap" style="flex:1">
          <small class="tip">Resultado</small>
          <img id="annotated" alt="resultado"/>
        </div>
      </div>

      <div id="status" class="tip" style="margin-top:8px"></div>
    </section>

    <p class="tip" style="text-align:center;margin-top:12px">
      Desenvolvido por <strong>Madalena de Oliveira Barbosa</strong>, 2025
    </p>
  </div>

<script>
const API = window.location.origin;
let currentFile = null;
let stream = null;
let lastClass = null;

function setStatus(t){ document.getElementById('status').textContent = t || ""; }

function sleep(ms){ return new Promise(r=>setTimeout(r,ms)); }

async function compressImage(file, maxSide=1024, quality=0.85){
  return new Promise((resolve,reject)=>{
    const img = new Image();
    img.onload=()=>{
      const scale=Math.min(1, maxSide/Math.max(img.width,img.height));
      const w=Math.round(img.width*scale), h=Math.round(img.height*scale);
      const cv=document.getElementById('canvas'), ctx=cv.getContext('2d');
      cv.width=w; cv.height=h; ctx.drawImage(img,0,0,w,h);
      cv.toBlob(b=>{
        if(!b) return reject(new Error("compress fail"));
        resolve(new File([b], file.name||"photo.jpg", {type:"image/jpeg"}));
      },"image/jpeg",quality);
    };
    img.onerror=reject;
    img.src=URL.createObjectURL(file);
  });
}

const inputGallery = document.getElementById('fileGallery');
const inputCamera  = document.getElementById('fileCamera');

document.getElementById('btnPick').onclick = () => { inputGallery.value=""; inputGallery.click(); };
inputGallery.onchange = () => useLocalFile(inputGallery.files?.[0]);
inputCamera.onchange  = () => useLocalFile(inputCamera.files?.[0]);

async function useLocalFile(f){
  if(!f) return;
  currentFile = await compressImage(f);
  document.getElementById('preview').src = URL.createObjectURL(currentFile);
  document.getElementById('preview').style.display = "block";
  document.getElementById('video').style.display = "none";
  document.getElementById('btnSend').disabled = false;
  document.getElementById('btnChat').style.display = "none";
  lastClass = null;
  setStatus("Imagem pronta para envio.");
}

const btnCam  = document.getElementById('btnCam');
const btnShot = document.getElementById('btnShot');
const video   = document.getElementById('video');

btnCam.onclick = async () => {
  try{
    if(!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia)) throw new Error("no gum");
    stream = await navigator.mediaDevices.getUserMedia({ video:{ facingMode:{ideal:"environment"} } });
    video.srcObject = stream;
    video.style.display = "block";
    document.getElementById('preview').style.display = "none";
    btnShot.style.display = "inline-block";
    setStatus("Câmera aberta.");
  }catch(e){
    inputCamera.value = "";
    inputCamera.click(); // fallback para WebView
  }
};

btnShot.onclick = () => {
  const cv=document.getElementById('canvas'), ctx=cv.getContext('2d');
  cv.width=video.videoWidth; cv.height=video.videoHeight;
  ctx.drawImage(video,0,0);
  cv.toBlob(async b=>{
    currentFile = await compressImage(new File([b],"camera.jpg",{type:"image/jpeg"}));
    document.getElementById('preview').src = URL.createObjectURL(currentFile);
    document.getElementById('preview').style.display = "block";
    video.style.display = "none";
    btnShot.style.display = "none";
    if(stream){ stream.getTracks().forEach(t=>t.stop()); stream=null; }
    document.getElementById('btnSend').disabled = false;
    document.getElementById('btnChat').style.display = "none";
    lastClass = null;
    setStatus("Foto capturada.");
  },"image/jpeg",0.92);
};

document.getElementById('btnSend').onclick = async () => {
  if(!currentFile) return;
  document.getElementById('btnSend').disabled = true;
  setStatus("Enviando...");
  try{
    const fd=new FormData(); fd.append("file", currentFile, currentFile.name||"image.jpg");
    const r=await fetch(API + "/predict", {method:"POST", body:fd});
    const d=await r.json();

    if(d.ok===false && d.warming_up){ setStatus("Aquecendo o modelo… tente novamente."); return; }
    if(d.ok===false){ setStatus("Erro: " + (d.error||"desconhecido")); return; }

    if(d.image_b64){ document.getElementById('annotated').src = d.image_b64; }
    else if(d.image_url){
      const url = d.image_url.startsWith("http")? d.image_url : (API + d.image_url);
      document.getElementById('annotated').src = url;
    }

    const chatBtn = document.getElementById('btnChat');
    if(d.top_pred && d.top_pred.classe){
      lastClass = d.top_pred.classe;
      chatBtn.style.display = "inline-block";
      chatBtn.onclick = () => { location.href = "/info?pepper=" + encodeURIComponent(lastClass); };
      setStatus(`Detectado: ${lastClass} · caixas: ${d.num_dets}`);
    }else{
      chatBtn.style.display = "none";
      lastClass = null;
      setStatus("Nenhuma pimenta detectada.");
    }
  }catch(e){
    setStatus("Falha ao chamar a API.");
  }finally{
    document.getElementById('btnSend').disabled = false;
  }
};
</script>
</body>
</html>
"""
    return HTMLResponse(content=html)

# ===================== CHAT (/info) =====================

# ----------------- /info (CHAT) -----------------
@app.get("/info")
def info():
def info(req: Request):
    html = r"""
<!doctype html>
<html lang="pt-br">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"/>
  <title>Chat: Pimentas</title>
  <title>Chat: Pimenta</title>
  <link rel="icon" href="/static/pimenta-logo.png" type="image/png" sizes="any">
  <style>
    :root{ --bg:#f7fafc; --card:#ffffff; --fg:#0f172a; --muted:#475569; --line:#e2e8f0; --accent:#16a34a;}
    :root{ --bg:#f7fafc; --card:#ffffff; --fg:#0f172a; --muted:#475569; --line:#e2e8f0; --accent:#16a34a; }
    *{box-sizing:border-box}
    html,body{margin:0;background:var(--bg);color:var(--fg);font:400 16px/1.45 system-ui,-apple-system,Segoe UI,Roboto}
    .wrap{max-width:980px;margin:auto;padding:16px}
    html,body{ margin:0;background:var(--bg);color:var(--fg);font:400 16px/1.45 system-ui,-apple-system,Segoe UI,Roboto }
    .wrap{max-width:980px;margin:auto;padding:12px 12px 0}
    header{display:flex;align-items:center;gap:10px}
    header h1{font-size:20px;margin:0}
    header h1{font-size:18px;margin:0}
    .btn{appearance:none;border:1px solid var(--line);background:#fff;color:var(--fg);padding:8px 12px;border-radius:10px;cursor:pointer;font-weight:600}
    .card{background:var(--card);border:1px solid var(--line);border-radius:16px;padding:12px;box-shadow:0 4px 24px rgba(15,23,42,.06)}
    .messages{border:1px solid var(--line);border-radius:12px;padding:10px;background:#fff;height:55vh;min-height:320px;overflow:auto}
    .msg{margin:6px 0;display:flex}
    .bubble{max-width:80%;padding:10px 12px;border-radius:12px;border:1px solid var(--line);white-space:pre-wrap}
    .me{justify-content:flex-end}
    .bme{background:#eef2ff;border-color:#c7d2fe}
    .chips{display:flex;gap:8px;flex-wrap:wrap;margin:8px 0}
    .chip{border:1px solid var(--line);border-radius:999px;padding:6px 10px;background:#fff;cursor:pointer;font-size:13px}
    .messages{border:1px solid var(--line);border-radius:12px;padding:10px;background:#fff;height:58vh;min-height:290px;overflow:auto}
    .msg{margin:6px 0;display:flex}
    .msg.me{justify-content:flex-end}
    .bubble{max-width:80%;padding:8px 10px;border-radius:12px;border:1px solid var(--line);white-space:pre-wrap}
    .bubble.me{background:#eef2ff;border-color:#c7d2fe}
    .composer{display:flex;gap:8px;margin-top:8px;position:sticky;bottom:0;background:var(--card);padding:8px;border-top:1px solid var(--line);border-radius:0 0 12px 12px}
    .input{flex:1;border:1px solid var(--line);border-radius:12px;padding:10px}
    .btn{appearance:none;border:1px solid var(--line);background:var(--accent);color:#fff;padding:10px 14px;border-radius:12px;cursor:pointer;font-weight:600}
    a.back{margin-left:auto;border:1px solid var(--line);padding:6px 10px;border-radius:10px;text-decoration:none;color:var(--fg);background:#fff}
    .dock{position:sticky;bottom:0;left:0;right:0;background:#ffffffd9;border-top:1px solid var(--line);padding:10px;border-radius:12px;backdrop-filter:saturate(140%) blur(6px)}
    .row{display:flex;gap:8px;align-items:center}
    input[type=text]{flex:1;border:1px solid var(--line);border-radius:10px;padding:10px 12px;font:inherit}
    .btn.accent{background:var(--accent);border-color:var(--accent);color:#fff}
    a.back{ text-decoration:none; }
  </style>
</head>
<body>
<div class="wrap">
  <header>
    <img src="/static/pimenta-logo.png" alt="Logo" width="28" height="28" onerror="this.style.display='none'">
    <h1 id="title">Chat de Pimentas</h1>
    <a class="back" href="/ui">← Voltar</a>
  </header>

  <section class="card">
    <div class="chips" id="chips">
      <span class="chip" data-q="O que é?">O que é?</span>
      <span class="chip" data-q="Usos/receitas">Usos/receitas</span>
      <span class="chip" data-q="Conservação">Conservação</span>
      <span class="chip" data-q="Substituições">Substituições</span>
      <span class="chip" data-q="Origem">Origem</span>
  <div class="wrap">
    <header>
      <a class="back" href="/ui"><button class="btn">← Voltar</button></a>
      <h1 id="title">Chat</h1>
    </header>

    <div class="card" style="margin-top:8px">
      <div class="chips">
        <span class="chip" data-q="O que é?">O que é?</span>
        <span class="chip" data-q="Usos e receitas">Usos/receitas</span>
        <span class="chip" data-q="Conservação">Conservação</span>
        <span class="chip" data-q="Substituições">Substituições</span>
        <span class="chip" data-q="Origem">Origem</span>
      </div>
      <div id="messages" class="messages"></div>

      <div class="dock">
        <div class="row">
          <input id="inputMsg" type="text" placeholder="Digite 1–5 (atalhos) ou faça uma pergunta livre..."/>
          <button id="btnSend" class="btn accent">Enviar</button>
        </div>
      </div>
    </div>

    <div id="messages" class="messages"></div>
    <p class="row" style="justify-content:center;color:#475569;margin:8px 0 16px">Desenvolvido por <strong>&nbsp;Madalena de Oliveira Barbosa</strong>, 2025</p>
  </div>

<script>
const qs = new URLSearchParams(location.search);
const API = window.location.origin;
const pepper = qs.get("pepper") || "";

let KB = null;     // JSON completo
let DOC = null;    // documento da pimenta

function el(tag, cls, text){ const e=document.createElement(tag); if(cls) e.className=cls; if(text!=null) e.textContent=text; return e; }
function scrollEnd(){ const box=document.getElementById('messages'); box.scrollTop = box.scrollHeight; }

function norm(s){
  return (s||"")
    .toLowerCase()
    .replace(/-?pepper/g,"")
    .normalize('NFD').replace(/[\u0300-\u036f]/g,'')
    .replace(/[^a-z0-9]/g,'');
}

async function loadKB(){
  try{
    const r = await fetch("/static/pepper_info.json", {cache:"no-store"});
    KB = await r.json();
  }catch(e){ KB = {}; }
}

function pickDoc(name){
  if(!KB || typeof KB !== "object") return null;
  const keys = Object.keys(KB);
  const want = norm(name);
  const idx = {};
  for(const k of keys){ idx[norm(k)] = k; }
  if(idx[want]) return KB[idx[want]];
  for(const k of keys){
    const nk = norm(k);
    if(want && (want.includes(nk) || nk.includes(want))) return KB[k];
  }
  return null;
}

function putMsg(text, me=false){
  const wrap = el("div","msg"+(me?" me":""));
  const b = el("div","bubble"+(me?" bme":""), null);
  b.innerHTML = String(text||"").replace(/\n/g,"<br>");
  wrap.appendChild(b);
  document.getElementById('messages').appendChild(wrap);
  scrollEnd();
}

function answerLocal(q){
  if(!DOC){
    return { text:"Ainda não tenho dados desta pimenta.", weak:true };
  }
  const msg = (q||"").toLowerCase();
  const parts = [];
  const has = (k) => DOC[k]!=null && String(DOC[k]).trim()!=="";

  if(/(o que|o que é|\bo que e\b|\bdefini|sobre )/.test(msg)){
    if(has("descricao")) parts.push(String(DOC.descricao));
  }
  if(/uso|receita|culin|molho|chutney|prato|cozinhar/.test(msg)){
    if(has("usos")) parts.push("Usos: "+String(DOC.usos));
    if(has("receitas")) parts.push("Receitas: "+String(DOC.receitas));
  }
  if(/conserva|armazen|guardar|dur[aá]vel/.test(msg)){
    if(has("conservacao")) parts.push("Conservação: "+String(DOC.conservacao));
  }
  if(/substitui|alternativa|trocar/.test(msg)){
    const s = DOC.substituicoes || DOC.substituicoes_sugeridas;
    if(s) parts.push("Substituições: "+String(s));
  }
  if(/origem|hist[oó]ria|cultivo|plantio/.test(msg)){
    if(has("origem")) parts.push("Origem: "+String(DOC.origem));
  }

  if(!parts.length){
    const nome = DOC.nome || pepper || "pimenta";
    const base = [];
    if(has("descricao")) base.push("Sobre "+nome+": "+String(DOC.descricao));
    if(has("usos"))      base.push("Usos: "+String(DOC.usos));
    if(has("receitas"))  base.push("Receitas: "+String(DOC.receitas));
    if(has("conservacao")) base.push("Conservação: "+String(DOC.conservacao));
    if(has("origem"))    base.push("Origem: "+String(DOC.origem));
    return { text: base.join("\n\n") || "Sem informações locais registradas.", weak:true };
  }
  return { text: parts.join("\n\n"), weak:false };
}

async function ask(q){
  let L = answerLocal(q);
  let a = L.text;
  let weak = L.weak;

  if(weak && DOC){
    try{
      const r = await fetch("/ai", {
        method:"POST",
        headers:{"Content-Type":"application/json"},
        body: JSON.stringify({ pepper:(DOC?.nome || pepper || ""), q })
      });
      if(r.ok){
        const j = await r.json();
        if(j && j.ok && j.text){ a = j.text; weak = false; }
      }
    }catch(e){}
  }

  if(weak){
    try{
      const g = await fetch("/ai_general", {
        method:"POST",
        headers:{"Content-Type":"application/json"},
        body: JSON.stringify({ q })
      });
      if(g.ok){
        const gj = await g.json();
        if(gj && gj.ok && gj.text){ a = gj.text; weak = false; }
      }
    }catch(e){}
  }

  if(weak){
    try{
      const w = await fetch("/webqa", {
        method:"POST",
        headers:{"Content-Type":"application/json"},
        body: JSON.stringify({ q })
      });
      if(w.ok){
        const wj = await w.json();
        if(wj && wj.ok && wj.text){ a = wj.text; weak = false; }
      }
    }catch(e){}
  }

  return a || "Não encontrei uma boa resposta agora.";
}

document.getElementById('btnSend').onclick = async () => {
  const input = document.getElementById('inputMsg');
  let q = (input.value || "").trim();
  if(!q) return;
  input.value = "";

  if(/^\s*[1-5]\s*$/.test(q)){
    const n = Number(q.trim());
    const map = {
      1:"O que é?",
      2:"Usos e receitas",
      3:"Conservação",
      4:"Substituições",
      5:"Origem"
    };
    q = map[n] || q;
  }

  putMsg(q,true);
  const a = await ask(q);
  putMsg(a,false);
};

document.querySelector(".chips").addEventListener("click",(e)=>{
  const t = e.target.closest(".chip"); if(!t) return;
  const q = t.getAttribute("data-q");
  putMsg(q,true);
  ask(q).then(a=>putMsg(a,false));
});

(async function(){
  await loadKB();
  DOC = pickDoc(pepper) || null;
  const title = document.getElementById('title');
  title.textContent = "Chat: " + (DOC?.nome || pepper || "Pimenta");
  putMsg("Use os botões ou faça sua pergunta. Respondo com base no arquivo local e, se precisar, amplio com IA/Web.");
})();
</script>
</body>
</html>
"""
    return HTMLResponse(content=html)

# ===================== IA (opcional) =====================

def _openai_chat(messages, temperature=0.2, max_tokens=300):
    if not OPENAI_KEY:
        return None, "Sem OPENAI_API_KEY"
    try:
        url = "https://api.openai.com/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {OPENAI_KEY}",
            "Content-Type": "application/json",
        }
        payload = {
            "model": OPENAI_MODEL,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
        }
        r = requests.post(url, headers=headers, json=payload, timeout=30)
        j = r.json()
        text = j.get("choices",[{}])[0].get("message",{}).get("content","").strip()
        if not text:
            return None, "Sem texto"
        return text, None
    except Exception as e:
        return None, str(e)

@app.post("/ai")
def ai_chat(data: dict):
    pepper = data.get("pepper","")
    q = data.get("q","")
    if not q:
        return {"ok": False, "text": "Pergunta vazia."}
    system = f"Você é um assistente culinário especializado em pimentas. Responda com frases curtas, claras e úteis. Pimenta alvo: {pepper}."
    text, err = _openai_chat([
        {"role":"system","content":system},
        {"role":"user","content":q}
    ])
    if text:
        return {"ok": True, "text": text}
    else:
        # fallback neutro
        return {"ok": True, "text": "Desculpe, não consegui consultar a IA agora."}

@app.post("/ai_general")
def ai_general(data: dict):
    q = data.get("q","")
    if not q:
        return {"ok": False, "text":"Pergunta vazia."}
    system = "Você é um assistente útil. Responda de forma breve e objetiva."
    text, err = _openai_chat([
        {"role":"system","content":system},
        {"role":"user","content":q}
    ])
    if text:
        return {"ok": True, "text": text}
    else:
        return {"ok": True, "text": "No momento, não consegui ampliar com IA."}

# ===================== Tavily Web QA (opcional) =====================

@app.post("/webqa")
def webqa(data: dict):
    q = data.get("q","")
    if not q or not TAVILY_KEY:
        return {"ok": False, "text": ""}
    try:
        r = requests.post(
            "https://api.tavily.com/search",
            json={
                "api_key": TAVILY_KEY,
                "query": q,
                "search_depth": "basic",
                "include_answer": True,
                "include_raw_content": False,
                "max_results": 3
            },
            timeout=30
        )
        j = r.json()
        ans = j.get("answer") or ""
        return {"ok": True, "text": ans}
    except Exception:
        return {"ok": True, "text": ""}

# ===================== RUN (Render usa gunicorn/uvicorn) =====================

    <div class="composer">
      <input id="inputMsg" class="input" placeholder="Digite 1–5 (atalhos) ou faça uma pergunta livre..."/>
      <button id="
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=int(os.getenv("PORT", "8000")))
